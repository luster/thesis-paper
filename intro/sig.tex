Domain knowledge of discrete audio signals and systems better informs our decisions for an audio denoising system, so some background information on signals and systems as it pertains to this thesis is detailed below.

\subsubsection{Signals}
We deal exclusively with discrete-time audio signals in this thesis. A discrete-time audio signal $x[n]$ is represented as a sequence of numbers (samples), where each integer-valued slot $n$ in the sequence corresponds to a unit of time based on the sampling frequency $f_s$. This comes from sampling the continuous-time audio signal $x_c(t)$:
\begin{equation}
x[n] = x_c(nT)
\end{equation}

where $T=1/f_s$.
For example, a 1-second speech signal sampled at 8kHz has 8000 samples. Furthermore, digital signals also have discrete valued sample amplitudes. For the purposes of this thesis, the bit depths of computers we use for analysis are high enough to allow for perfect reconstruction between continuous-time signals and digital signals.

We also assume signals collected have been properly sampled according to the Nyquist-Shannon sampling theorem, which states that a discrete-time signal must be sampled at at least twice the highest frequency present in the signal to prevent aliasing of different frequencies. For example, speech signals genearlly have information up to 8kHz, so many speech signals are sampled at 16kHz. Music is more complex in that signals often span up to about 20kHz, so CD quality recordings are often sampled at 44.1kHz or higher. For this thesis, we use recordings sampled at 44.1kHz or lower.


\subsubsection{Convolution}
The discrete-time convolution operation takes two sequences $x[n]$ and $h[n]$ and outputs a third sequence $y[n] = x[n] * h[n]$:

\begin{equation}
y[n] = \sum_{k=-\infty}^{\infty} x[k]h[n-k]
\end{equation}

A linear, time-invariant (LTI) system is characterized by its impulse response $h[n]$, which allows us to determine samples $y[n]$ when $x[n]$ is subject to $h[n]$. For the purposes of this thesis, our underlying clean signal $x[n]$ might be subject to the conditions of an acoustic environment $h[n]$ and crowd noise $N[n]$:
\begin{equation}
y[n] = h[n]*x[n]+N[n]
\end{equation}

In this scenario, our system would attempt to recover $h[n]*x[n]$ and possibly $x[n]$ if the acoustic environment were deemed ``noisy enough.''

One of our proposed systems also incorporates convolutional neural networks (CNN), which use convolutions between samples instead of simple linear combinations (discussed later).

\subsubsection{Frequency Transforms}



\subsubsection{Windowing and Perfect Reconstruction}
