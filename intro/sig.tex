Domain knowledge of discrete audio signals and systems better informs our decisions for an audio denoising system, so some background information on signals and systems as it pertains to this thesis is detailed below.

\subsubsection{Signals}
We deal exclusively with discrete-time audio signals in this thesis. A discrete-time audio signal $x[n]$ is represented as a sequence of numbers (samples), where each integer-valued slot $n$ in the sequence corresponds to a unit of time based on the sampling frequency $f_s$. This comes from sampling the continuous-time audio signal $x_c(t)$:

\begin{equation}
x[n] = x_c(nT)
\end{equation}

where $T=1/f_s$.
For example, a 1-second speech signal sampled at 8kHz has 8000 samples. Furthermore, digital signals also have discrete valued sample amplitudes. For the purposes of this thesis, the bit depths of computers we use for analysis are high enough to allow for perfect reconstruction between continuous-time signals and digital signals.

We also assume signals collected have been properly sampled according to the Nyquist-Shannon sampling theorem, which states that a discrete-time signal must be sampled at at least twice the highest frequency present in the signal to prevent aliasing of different frequencies. For example, speech signals genearlly have information up to 8kHz, so many speech signals are sampled at 16kHz. Music is more complex in that signals often span up to about 20kHz, so CD quality recordings are often sampled at 44.1kHz or higher. For this thesis, we use recordings sampled at 44.1kHz or lower.


\subsubsection{Convolution} % TODO: figure with basic flip/slide convolution
The discrete-time convolution operation takes two sequences $x[n]$ and $h[n]$ and outputs a third sequence $y[n] = x[n] * h[n]$:

\begin{equation}
y[n] = \sum_{k=-\infty}^{\infty} x[k]h[n-k]
\end{equation}

Convolution is commutative, so $x[n] * h[n] = h[n] * x[n]$ holds true.

A linear, time-invariant (LTI) system is characterized by its impulse response $h[n]$, which allows us to determine samples $y[n]$ when $x[n]$ is subject to $h[n]$. For the purposes of this thesis, our underlying clean signal $x[n]$ might be subject to the conditions of an acoustic environment $h[n]$ and crowd noise $N[n]$:

\begin{equation}
y[n] = h[n]*x[n]+N[n]
\end{equation}

In this scenario, our system would attempt to recover $h[n]*x[n]$ and possibly even $x[n]$ if the acoustic environment were deemed ``noisy enough'' due to echo and reverberation.

One of our proposed systems also incorporates convolutional neural networks (CNN) which use convolutions between frames of samples instead of simple linear combinations (discussed later).

\subsubsection{Frequency Transforms} % TODO: figure with time and frequency graph
In some of our proposed systems, we use a frequency transformed version of the input signal as a preprocessing step to the system input. While no new information is gained from transforming the input, networks often respond better to determining the value of the magnitude of varying frequencies at a time slice instead of the individual time samples.

The frequency transform we use in this thesis is the discrete-time Fourier transform (DTFT). A sequence of $N$ discrete-time samples is transformed into another sequence of $N$ samples where each index then corresponds to a frequency bin. The DTFT $X[k]$ of a signal $x[n]$ is given by the following:

\begin{equation}
X[k] = \sum_{n=0}^{N-1} x[n] W_N^{kn}
\end{equation}

where the twiddle factor $W_N$ is given by $W_N=e^{-j(2\pi/N)}$. Then the reconstruction of $x[n]$ from $X[k]$ is given by:

\begin{equation}
x[n]=\dfrac{1}{N} \sum_{k=0}^{N-1} X[k] W_N^{-kn}
\end{equation}

In this thesis, we also exploit the main duality between the time and frequency domain using the convolution theorem, which states that convolution in time is equivalent to multiplication in frequency and vise versa:

\begin{equation}
\mathscr{F} \{h[n] * x[n]\} = H[k] X[k]
\end{equation}
\begin{equation}
\mathscr{F}^{-1} \{H[k] * X[k]\} = h[n] x[n]
\end{equation}

This allows us to effectively treat our network as a non-linear filter that can denoise small time/frequency slices of our noisy signal, which can then be pieced back together using overlap-add resynthesis. We detail this in the next section.

\subsubsection{Windowing and Perfect Reconstruction}
To window a signal is to multiply a window function $w[n]$ by the frame, i.e. $w[n]x[n]$ over the frame length $N$. Because we are training a network to denoise small segments of a larger audio signal, we window the signal segments. This accommodates the finite-length requirement of the DTFT and helps to prevent spectral leakage. [DSPBOOK]

Also, to be able to properly reconstruct our signal, we use a window function and corresponding overlapping frame percentage to accomplish perfect reconstruction. The corresponding overlapping frame percentage is set such that the window sums to a constant for all time. For example, a rectangular window $w[n]=1$ over an interval of length $N$ has an overlap of 0\% to sum to a constant 1 for all time. Another popular window is the Hanning window, defined over an interval $N$ by the following:

\begin{equation}
w[n] = \dfrac{1}{2} \bigg( 1-\cos \bigg(\dfrac{2 \pi n}{N - 1} \bigg)\bigg)
\end{equation}

For the Hann window, the perfect reconstruction overlap is a frame length of $N=50\%$.

\subsubsection{Window Size and Frequency v. Time Resolution Tradeoff}

\subsubsection{Noise and Signal-to-Noise Ratio}
Since we are trying to denoise audio signals, we must discuss how we measure noise. One of the most common measures of degradation of signal quality from additive noise is signal-to-noise ratio (SNR), defined as the ratio of signal variance to noise variance. [DSP] For the signal $y[n] = x[n] + N[n]$, where $x[n]$ is the signal of interest and $N[n]$ is the additive noise, the SNR is defined as

\begin{equation}
SNR = \dfrac{\sigma_{x}^2}{\sigma_{n}^2}
\end{equation}

where $\sigma^{2}$ refers to the variance of the signal in question over some time interval. For the purposes of this thesis, we achieve desired a desired SNR for a simulation by scaling the noise to match the variance to the signal, then scaling the noise or the signal to achieve the desired SNR. % Example about x[n] and N[n] having different scales, then scaling them and using k value to achieve desired SNR.

\subsubsection{Magnitude and Phase Spectrum}
