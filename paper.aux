\relax 
\citation{stow}
\citation{stow}
\citation{liu2014experiments}
\citation{stow}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Machine Learning}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Regression}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Overfitting and Curse of Dimensionality}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Loss functions and Regularization}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}Gradient Stuff?}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Neural Networks}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Dense Layer}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Convolutional Layer}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Nonlinearity Choice}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Minibatches}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5}Batch Normalization}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6}Weight Updates}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Signals and Systems}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Signals}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Convolution}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Frequency Transforms}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.4}Windowing and Perfect Reconstruction}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.5}Window Size and Frequency v. Time Resolution Tradeoff}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.6}Noise and Signal-to-Noise Ratio}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.7}Magnitude and Phase Spectrum}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Signal Model and Data}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Network Input and Output}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Signal and Noise Choices}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Other Network Parameters}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {4}De-noising Architectures}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Supervised Autoencoder}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Partitioned Autoencoder}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Phase Reconstruction}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Curro Autoencoder}{13}}
\citation{stow}
\citation{stow}
\citation{stow}
\citation{stow}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Supervised Autoencoder}{14}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Batch Normalized Input}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Loss at various SNRs for Supervised Single-Layer Autoencoder with Batch Normalization at the Input\relax }}{14}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Non-Batch Normalized Input}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Partitioned Autoencoder}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Partitioned Curro Autoencoder}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Comparison of Loss Convergence}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Comparison of Mean Squared Error Convergence}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces MSE at various SNRs for Supervised Single-Layer Autoencoder with Batch Normalization at the Input\relax }}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Loss at various SNRs for Supervised Single-Layer Autoencoder without Batch Normalization at the Input\relax }}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions and Future Work}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Conclusions}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces MSE at various SNRs for Supervised Single-Layer Autoencoder with Batch Normalization at the Input\relax }}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Loss at various SNRs for Single-Layer Partitioned Autoencoder\cite  {stow}\relax }}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Future Work}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Models}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces MSE at various SNRs for Single-Layer Partitioned Autoencoder\cite  {stow}\relax }}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Loss at various SNRs for Single-Layer Curro Autoencoder\relax }}{17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2}Data}{17}}
\citation{*}
\bibdata{bib}
\bibcite{stow}{1}
\bibcite{liu2014experiments}{2}
\bibcite{bishop2006pattern}{3}
\bibcite{baldi2012complex}{4}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces MSE at various SNRs for Single-Layer Curro Autoencoder\relax }}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Loss Comparison of Various Networks at -6 dB\relax }}{18}}
\bibcite{xu2014experimental}{5}
\bibcite{vincent2010stacked}{6}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Loss Comparison of Various Networks at -3 dB\relax }}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Loss Comparison of Various Networks at 0 dB\relax }}{19}}
\bibcite{ishii2013reverberant}{7}
\bibcite{alan1989discrete}{8}
\bibcite{gold2011speech}{9}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Loss Comparison of Various Networks at 3 dB\relax }}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Loss Comparison of Various Networks at 6 dB\relax }}{20}}
\bibcite{kayserdenoising}{10}
\bibcite{zolzer2008digital}{11}
\bibcite{hinton2006reducing}{12}
\bibcite{rad2012phase}{13}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces MSE Comparison of Networks at -6 dB\relax }}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces MSE Comparison of Networks at -3 dB\relax }}{21}}
\bibcite{2016arXiv160502688short}{14}
\bibcite{sander_dieleman_2015_27878}{15}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces MSE Comparison of Networks at 0 dB\relax }}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces MSE Comparison of Networks at 3 dB\relax }}{22}}
\bibcite{ioffe2015batch}{16}
\bibcite{VincentPLarochelleH2008}{17}
\bibcite{ICML08}{18}
\bibcite{da}{19}
\bibstyle{IEEEtran}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces MSE Comparison of Networks at 6 dB\relax }}{23}}
