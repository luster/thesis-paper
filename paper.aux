\relax 
\citation{stow}
\citation{stow}
\citation{liu2014experiments}
\citation{stow}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Machine Learning}{3}}
\citation{bishop}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Regression}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Overfitting and Curse of Dimensionality}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Loss functions and Regularization}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}Gradient Stuff?}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Neural Networks}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example neural network}}{5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:nn}{{1}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Dense Layer}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Autoencoder}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Convolutional Layer}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Nonlinearity Choice}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5}Minibatches}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6}Batch Normalization}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.7}Weight Updates}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Signals and Systems}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Signals}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Convolution}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Frequency Transforms}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.4}Windowing and Perfect Reconstruction}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.5}Window Size and Frequency v. Time Resolution Tradeoff}{11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.6}Noise and Signal-to-Noise Ratio}{11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.7}Magnitude and Phase Spectrum}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Signal Model and Data}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Network Input and Output}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Signal and Noise Choices}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Other Network Parameters}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {4}De-noising Architectures}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Supervised Autoencoder}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Partitioned Autoencoder}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Phase Reconstruction}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Curro Autoencoder}{15}}
\citation{stow}
\citation{stow}
\citation{stow}
\citation{stow}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Supervised Autoencoder}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Batch Normalized Input}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Loss at various SNRs for Supervised Single-Layer Autoencoder with Batch Normalization at the Input\relax }}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Non-Batch Normalized Input}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Partitioned Autoencoder}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Partitioned Curro Autoencoder}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Comparison of Loss Convergence}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Comparison of Mean Squared Error Convergence}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces MSE at various SNRs for Supervised Single-Layer Autoencoder with Batch Normalization at the Input\relax }}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Loss at various SNRs for Supervised Single-Layer Autoencoder without Batch Normalization at the Input\relax }}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions and Future Work}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Conclusions}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces MSE at various SNRs for Supervised Single-Layer Autoencoder with Batch Normalization at the Input\relax }}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Loss at various SNRs for Single-Layer Partitioned Autoencoder\cite  {stow}\relax }}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Future Work}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Models}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces MSE at various SNRs for Single-Layer Partitioned Autoencoder\cite  {stow}\relax }}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Loss at various SNRs for Single-Layer Curro Autoencoder\relax }}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2}Data}{19}}
\citation{*}
\bibdata{bib}
\bibcite{stow}{1}
\bibcite{liu2014experiments}{2}
\bibcite{bishop}{3}
\bibcite{baldi2012complex}{4}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces MSE at various SNRs for Single-Layer Curro Autoencoder\relax }}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Loss Comparison of Various Networks at -6 dB\relax }}{20}}
\bibcite{xu2014experimental}{5}
\bibcite{vincent2010stacked}{6}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Loss Comparison of Various Networks at -3 dB\relax }}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Loss Comparison of Various Networks at 0 dB\relax }}{21}}
\bibcite{ishii2013reverberant}{7}
\bibcite{alan1989discrete}{8}
\bibcite{gold2011speech}{9}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Loss Comparison of Various Networks at 3 dB\relax }}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Loss Comparison of Various Networks at 6 dB\relax }}{22}}
\bibcite{kayserdenoising}{10}
\bibcite{zolzer2008digital}{11}
\bibcite{hinton2006reducing}{12}
\bibcite{rad2012phase}{13}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces MSE Comparison of Networks at -6 dB\relax }}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces MSE Comparison of Networks at -3 dB\relax }}{23}}
\bibcite{2016arXiv160502688short}{14}
\bibcite{sander_dieleman_2015_27878}{15}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces MSE Comparison of Networks at 0 dB\relax }}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces MSE Comparison of Networks at 3 dB\relax }}{24}}
\bibcite{ioffe2015batch}{16}
\bibcite{VincentPLarochelleH2008}{17}
\bibcite{ICML08}{18}
\bibcite{da}{19}
\bibstyle{IEEEtran}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces MSE Comparison of Networks at 6 dB\relax }}{25}}
