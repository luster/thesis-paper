\relax 
\citation{stow}
\citation{stow}
\citation{liu2014experiments}
\citation{stow}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Machine Learning}{3}}
\citation{bishop}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Regression}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Neural Networks}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example neural network}}{5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:nn}{{1}{5}}
\citation{stow}
\citation{bishop}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Dense Layer}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Denoising Autoencoder}{6}}
\citation{liu2014experiments}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Network Training}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Choice of Activation Function}{7}}
\citation{glorot2011deep}
\citation{wilson2003general}
\citation{wilson2003general}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5}Minibatch Training}{8}}
\citation{ioffe2015batch}
\citation{ioffe2015batch}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6}Batch Normalization}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Signals and Systems}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Signals}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Convolution}{11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Frequency Transforms}{11}}
\citation{alan1989discrete}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.4}Windowing and Perfect Reconstruction}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.5}Window Size and Frequency v. Time Resolution Tradeoff}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.6}Noise and Signal-to-Noise Ratio}{14}}
\citation{stow}
\@writefile{toc}{\contentsline {section}{\numberline {3}Signal Model and Data}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Network Input and Output}{15}}
\newlabel{eq:siggy}{{24}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Signal and Noise Choices}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Other Network Parameters}{17}}
\citation{liu2014experiments}
\citation{liu2014experiments}
\citation{liu2014experiments}
\@writefile{toc}{\contentsline {section}{\numberline {4}De-noising Architectures}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Supervised Autoencoder}{19}}
\citation{liu2014experiments}
\citation{stow}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Modified Rectified Linear Unit Activation}}{20}}
\newlabel{fig:mrelu}{{2}{20}}
\citation{stow}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Partitioned Autoencoder}{21}}
\newlabel{eq:stowloss}{{34}{21}}
\citation{stow}
\citation{stow}
\citation{stow}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Example Partitioned Masking Matrix}}{22}}
\newlabel{fig:cmat}{{3}{22}}
\citation{stow}
\citation{liu2014experiments}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Phase Reconstruction}{23}}
\citation{stow}
\citation{stow}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Curro Autoencoder}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Curro Autoencoder Block Diagram}}{24}}
\newlabel{fig:currodiagram}{{4}{24}}
\citation{stow}
\citation{stow}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{27}}
\citation{sander_dieleman_2015_27878}
\citation{2016arXiv160502688short}
\citation{DBLP:journals/corr/KingmaB14}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Supervised Autoencoder}{29}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Batch Normalized Input}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Loss at various SNRs for Supervised Single-Layer Autoencoder with Batch Normalization at the Input\relax }}{29}}
\newlabel{fig:paris-bn-loss}{{5}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces MSE at various SNRs for Supervised Single-Layer Autoencoder with Batch Normalization at the Input\relax }}{30}}
\newlabel{fig:paris-bn-mse}{{6}{30}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Non-Batch Normalized Input}{30}}
\citation{stow}
\citation{stow}
\citation{stow}
\citation{stow}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Loss at various SNRs for Supervised Single-Layer Autoencoder without Batch Normalization at the Input\relax }}{31}}
\newlabel{fig:paris-loss}{{7}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces MSE at various SNRs for Supervised Single-Layer Autoencoder without Batch Normalization at the Input\relax }}{31}}
\newlabel{fig:paris-mse}{{8}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Loss at various SNRs for Single-Layer Partitioned Autoencoder\cite  {stow}\relax }}{32}}
\newlabel{fig:dan-loss}{{9}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces MSE at various SNRs for Single-Layer Partitioned Autoencoder\cite  {stow}\relax }}{32}}
\newlabel{fig:dan-mse}{{10}{32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Partitioned Autoencoder}{32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Partitioned Curro Autoencoder}{32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Comparison of Loss Convergence}{32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Comparison of Mean Squared Error Convergence}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Loss at various SNRs for Single-Layer Curro Autoencoder\relax }}{33}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces MSE at various SNRs for Single-Layer Curro Autoencoder\relax }}{33}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions and Future Work}{33}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Conclusions}{33}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Loss Comparison of Various Networks at -6 dB\relax }}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Loss Comparison of Various Networks at -3 dB\relax }}{34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Future Work}{34}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Models}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Loss Comparison of Various Networks at 0 dB\relax }}{35}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Loss Comparison of Various Networks at 3 dB\relax }}{35}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2}Data}{35}}
\citation{*}
\bibdata{bib}
\bibcite{stow}{1}
\bibcite{liu2014experiments}{2}
\bibcite{bishop}{3}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Loss Comparison of Various Networks at 6 dB\relax }}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces MSE Comparison of Networks at -6 dB\relax }}{36}}
\bibcite{glorot2011deep}{4}
\bibcite{wilson2003general}{5}
\bibcite{ioffe2015batch}{6}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces MSE Comparison of Networks at -3 dB\relax }}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces MSE Comparison of Networks at 0 dB\relax }}{37}}
\bibcite{alan1989discrete}{7}
\bibcite{sander_dieleman_2015_27878}{8}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces MSE Comparison of Networks at 3 dB\relax }}{38}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces MSE Comparison of Networks at 6 dB\relax }}{38}}
\bibcite{2016arXiv160502688short}{9}
\bibcite{DBLP:journals/corr/KingmaB14}{10}
\bibcite{baldi2012complex}{11}
\bibcite{xu2014experimental}{12}
\bibcite{vincent2010stacked}{13}
\bibcite{ishii2013reverberant}{14}
\bibcite{gold2011speech}{15}
\bibcite{kayserdenoising}{16}
\bibcite{zolzer2008digital}{17}
\bibcite{hinton2006reducing}{18}
\bibcite{rad2012phase}{19}
\bibcite{VincentPLarochelleH2008}{20}
\bibcite{ICML08}{21}
\bibcite{da}{22}
\bibcite{DBLP:journals/corr/SonodaM16}{23}
\bibstyle{IEEEtran}
\@writefile{toc}{\contentsline {section}{\numberline {A}Simulation Code}{41}}
\gdef\minted@oldcachelist{,
  default.pygstyle,
  default-pyg-prefix.pygstyle,
  19d5ebfce0e0a4104e3babe49a7d6ea52b08b778.pygtex}
